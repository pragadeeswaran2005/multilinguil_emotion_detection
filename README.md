# Multilingual Emotion Detection in Voice

## Overview

This project focuses on detecting emotions from voice recordings across multiple languages using machine learning and deep learning techniques. The core goal is to classify audio inputs into emotional categories (e.g., happy, sad, angry) using extracted audio features.

## Key Features

* **Multilingual Support**: Designed to handle voice samples in different languages.
* **Emotion Classification**: Supports classification into multiple emotion categories.
* **Audio Feature Extraction**: Utilizes libraries such as `librosa` to extract meaningful features like MFCC, chroma, and mel spectrograms.
* **Modeling**: Employs deep learning models (e.g., LSTM or CNN) built using `TensorFlow` or `Keras` for emotion prediction.
* **Data Handling**: Includes preprocessing steps for loading and cleaning audio data.

## Workflow

1. **Import Libraries**: Essential libraries for audio processing, data manipulation, and modeling are loaded.
2. **Feature Extraction**: Extract features such as:

   * MFCCs (Mel-Frequency Cepstral Coefficients)
   * Chroma features
   * Mel Spectrogram
3. **Dataset Preparation**: Load audio files, extract features, and label the data.
4. **Model Design**: Define and train a neural network architecture for classification.
5. **Evaluation**: Use metrics such as accuracy, precision, recall, and confusion matrix to evaluate performance.

## Libraries Used

* `librosa`
* `numpy`, `pandas`
* `matplotlib`, `seaborn`
* `sklearn`
* `tensorflow` / `keras`

## Use Case

This project can be used for applications such as:

* Call center emotion analysis
* Virtual assistant response tuning
* Mental health monitoring
* Language learning feedback systems

## How to Run

1. Install required dependencies:

   ```bash
   pip install librosa matplotlib pandas scikit-learn tensorflow
   ```

2. Run the notebook step-by-step to process the data and train the model.

3. Use the trained model to predict emotions on new voice recordings.

---


